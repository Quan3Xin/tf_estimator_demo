{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras import models\n",
    "gpus= tf.config.list_physical_devices('GPU') # tf2.1版本该函数不再是experimental\n",
    "print(gpus) # 前面限定了只使用GPU1(索引是从0开始的,本机有2张RTX2080显卡)\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True) # 其实gpus本身就只有一个元素\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1' \n",
    "# In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 65, 2, 4, 5]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,65]\n",
    "import random\n",
    "c = random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple Braeburn': 0,\n",
       " 'Apple Crimson Snow': 1,\n",
       " 'Apple Golden 1': 2,\n",
       " 'Apple Golden 2': 3,\n",
       " 'Apple Golden 3': 4,\n",
       " 'Apple Granny Smith': 5,\n",
       " 'Apple Pink Lady': 6,\n",
       " 'Apple Red 1': 7,\n",
       " 'Apple Red 2': 8,\n",
       " 'Apple Red 3': 9,\n",
       " 'Apple Red Delicious': 10,\n",
       " 'Apple Red Yellow 1': 11,\n",
       " 'Apple Red Yellow 2': 12,\n",
       " 'Apricot': 13,\n",
       " 'Avocado': 14,\n",
       " 'Avocado ripe': 15,\n",
       " 'Banana': 16,\n",
       " 'Banana Lady Finger': 17,\n",
       " 'Banana Red': 18,\n",
       " 'Beetroot': 19,\n",
       " 'Blueberry': 20,\n",
       " 'Cactus fruit': 21,\n",
       " 'Cantaloupe 1': 22,\n",
       " 'Cantaloupe 2': 23,\n",
       " 'Carambula': 24,\n",
       " 'Cauliflower': 25,\n",
       " 'Cherry 1': 26,\n",
       " 'Cherry 2': 27,\n",
       " 'Cherry Rainier': 28,\n",
       " 'Cherry Wax Black': 29,\n",
       " 'Cherry Wax Red': 30,\n",
       " 'Cherry Wax Yellow': 31,\n",
       " 'Chestnut': 32,\n",
       " 'Clementine': 33,\n",
       " 'Cocos': 34,\n",
       " 'Dates': 35,\n",
       " 'Eggplant': 36,\n",
       " 'Ginger Root': 37,\n",
       " 'Granadilla': 38,\n",
       " 'Grape Blue': 39,\n",
       " 'Grape Pink': 40,\n",
       " 'Grape White': 41,\n",
       " 'Grape White 2': 42,\n",
       " 'Grape White 3': 43,\n",
       " 'Grape White 4': 44,\n",
       " 'Grapefruit Pink': 45,\n",
       " 'Grapefruit White': 46,\n",
       " 'Guava': 47,\n",
       " 'Hazelnut': 48,\n",
       " 'Huckleberry': 49,\n",
       " 'Kaki': 50,\n",
       " 'Kiwi': 51,\n",
       " 'Kohlrabi': 52,\n",
       " 'Kumquats': 53,\n",
       " 'Lemon': 54,\n",
       " 'Lemon Meyer': 55,\n",
       " 'Limes': 56,\n",
       " 'Lychee': 57,\n",
       " 'Mandarine': 58,\n",
       " 'Mango': 59,\n",
       " 'Mango Red': 60,\n",
       " 'Mangostan': 61,\n",
       " 'Maracuja': 62,\n",
       " 'Melon Piel de Sapo': 63,\n",
       " 'Mulberry': 64,\n",
       " 'Nectarine': 65,\n",
       " 'Nectarine Flat': 66,\n",
       " 'Nut Forest': 67,\n",
       " 'Nut Pecan': 68,\n",
       " 'Onion Red': 69,\n",
       " 'Onion Red Peeled': 70,\n",
       " 'Onion White': 71,\n",
       " 'Orange': 72,\n",
       " 'Papaya': 73,\n",
       " 'Passion Fruit': 74,\n",
       " 'Peach': 75,\n",
       " 'Peach 2': 76,\n",
       " 'Peach Flat': 77,\n",
       " 'Pear': 78,\n",
       " 'Pear Abate': 79,\n",
       " 'Pear Forelle': 80,\n",
       " 'Pear Kaiser': 81,\n",
       " 'Pear Monster': 82,\n",
       " 'Pear Red': 83,\n",
       " 'Pear Williams': 84,\n",
       " 'Pepino': 85,\n",
       " 'Pepper Green': 86,\n",
       " 'Pepper Red': 87,\n",
       " 'Pepper Yellow': 88,\n",
       " 'Physalis': 89,\n",
       " 'Physalis with Husk': 90,\n",
       " 'Pineapple': 91,\n",
       " 'Pineapple Mini': 92,\n",
       " 'Pitahaya Red': 93,\n",
       " 'Plum': 94,\n",
       " 'Plum 2': 95,\n",
       " 'Plum 3': 96,\n",
       " 'Pomegranate': 97,\n",
       " 'Pomelo Sweetie': 98,\n",
       " 'Potato Red': 99,\n",
       " 'Potato Red Washed': 100,\n",
       " 'Potato Sweet': 101,\n",
       " 'Potato White': 102,\n",
       " 'Quince': 103,\n",
       " 'Rambutan': 104,\n",
       " 'Raspberry': 105,\n",
       " 'Redcurrant': 106,\n",
       " 'Salak': 107,\n",
       " 'Strawberry': 108,\n",
       " 'Strawberry Wedge': 109,\n",
       " 'Tamarillo': 110,\n",
       " 'Tangelo': 111,\n",
       " 'Tomato 1': 112,\n",
       " 'Tomato 2': 113,\n",
       " 'Tomato 3': 114,\n",
       " 'Tomato 4': 115,\n",
       " 'Tomato Cherry Red': 116,\n",
       " 'Tomato Maroon': 117,\n",
       " 'Tomato Yellow': 118,\n",
       " 'Walnut': 119}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# the number of classes of images\n",
    "\n",
    "# 组装 label名称和标签名称 例如 {“name”：1}\n",
    "data_root_orig = \"/root/quan/fruits-360/Training/\"\n",
    "data_root = pathlib.Path(data_root_orig)\n",
    "label_name = sorted(item.name for item in data_root.glob('*/')\n",
    "                    if item.is_dir())\n",
    "values = [i for i in list(range(len(label_name)))]\n",
    "classes = dict(zip(label_name, values))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/quan/fruits-360/tfrecord\n",
      "['train.tfrecord-091', 'train.tfrecord-083', 'train.tfrecord-067', 'train.tfrecord-026', 'train.tfrecord-058', 'train.tfrecord-016', 'train.tfrecord-109', 'train.tfrecord-003', 'train.tfrecord-111', 'train.tfrecord-056', 'train.tfrecord-114', 'train.tfrecord-012', 'train.tfrecord-046', 'train.tfrecord-119', 'train.tfrecord-037', 'train.tfrecord-066', 'train.tfrecord-039', 'train.tfrecord-081', 'train.tfrecord-075', 'train.tfrecord-106', 'train.tfrecord-117', 'train.tfrecord-110', 'train.tfrecord-076', 'train.tfrecord-034', 'train.tfrecord-018', 'train.tfrecord-055', 'train.tfrecord-059', 'train.tfrecord-017', 'train.tfrecord-000', 'train.tfrecord-080', 'train.tfrecord-112', 'train.tfrecord-022', 'train.tfrecord-072', 'train.tfrecord-021', 'train.tfrecord-100', 'train.tfrecord-097', 'train.tfrecord-108', 'train.tfrecord-040', 'train.tfrecord-053', 'train.tfrecord-062', 'train.tfrecord-029', 'train.tfrecord-019', 'train.tfrecord-050', 'train.tfrecord-116', 'train.tfrecord-044', 'train.tfrecord-086', 'train.tfrecord-010', 'train.tfrecord-071', 'train.tfrecord-009', 'train.tfrecord-103', 'train.tfrecord-089', 'train.tfrecord-082', 'train.tfrecord-073', 'train.tfrecord-049', 'train.tfrecord-090', 'train.tfrecord-052', 'train.tfrecord-087', 'train.tfrecord-005', 'train.tfrecord-011', 'train.tfrecord-063', 'train.tfrecord-064', 'train.tfrecord-051', 'train.tfrecord-107', 'train.tfrecord-101', 'train.tfrecord-102', 'train.tfrecord-065', 'train.tfrecord-028', 'train.tfrecord-006', 'train.tfrecord-014', 'train.tfrecord-025', 'train.tfrecord-078', 'train.tfrecord-047', 'train.tfrecord-001', 'train.tfrecord-035', 'train.tfrecord-007', 'train.tfrecord-096', 'train.tfrecord-032', 'train.tfrecord-033', 'train.tfrecord-118', 'train.tfrecord-041', 'train.tfrecord-013', 'train.tfrecord-038', 'train.tfrecord-068', 'train.tfrecord-113', 'train.tfrecord-088', 'train.tfrecord-027', 'train.tfrecord-070', 'train.tfrecord-061', 'train.tfrecord-069', 'train.tfrecord-084', 'train.tfrecord-048', 'train.tfrecord-099', 'train.tfrecord-115', 'train.tfrecord-023', 'train.tfrecord-094', 'train.tfrecord-060', 'train.tfrecord-045', 'train.tfrecord-043', 'train.tfrecord-098', 'train.tfrecord-105', 'train.tfrecord-002', 'train.tfrecord-095', 'train.tfrecord-104', 'train.tfrecord-057', 'train.tfrecord-079', 'train.tfrecord-015', 'train.tfrecord-031', 'train.tfrecord-008', 'train.tfrecord-093', 'train.tfrecord-085', 'train.tfrecord-036', 'train.tfrecord-020', 'train.tfrecord-024', 'train.tfrecord-004', 'train.tfrecord-042', 'train.tfrecord-092', 'train.tfrecord-054', 'train.tfrecord-077', 'train.tfrecord-074', 'train.tfrecord-030']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/root/quan/fruits-360/tfrecord/\")\n",
    "print(os.getcwd())\n",
    "name_list = [k for _, _ , k in os.walk(\".\")]\n",
    "print(name_list[0])\n",
    "name_list = name_list[0]\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filenames = [name_list])\n",
    "raw_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def input_fn(filenames, training):\n",
    "#     dataset = tf.data.TFRecordDataset(filenames)\n",
    "#     dataset = dataset.map(parse_data)\n",
    " \n",
    "#     if training:\n",
    "#         dataset = dataset.shuffle(buffer_size=50000)\n",
    "#     dataset = dataset.batch(FLAGS.batch_size)\n",
    "#     if training:\n",
    "#         dataset = dataset.repeat()\n",
    " \n",
    "#     iterator = dataset.make_one_shot_iterator()\n",
    "#     features, labels = iterator.get_next()\n",
    "#     return features, labels\n",
    "def input_fn( record_list):\n",
    "    list_ds = tf.data.TFRecordDataset(filenames = record_list)\n",
    "   \n",
    "    dataset = list_ds.map(_parse_image_function)\n",
    "    data = dataset.map(decode_img)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def decode_img(data):\n",
    "    #list_ds = tf.data.TFRecordDataset(filenames = record_list)\n",
    "   \n",
    "    #data = list_ds.map(_parse_image_function)\n",
    "    img_raw = data[\"image_raw\"]\n",
    "#     height = data[\"height\"]\n",
    "    \n",
    "#     wight = data[\"width\"]\n",
    "    label = data[\"label\"]\n",
    "    \n",
    "    \n",
    "    img_tensor = tf.image.decode_jpeg(img_raw,channels=3)\n",
    "    #imgs = tf.image.resize(img_tensor, [10,10])\n",
    "    img = tf.image.convert_image_dtype(img_tensor, tf.float32)\n",
    "    \n",
    "    img = tf.image.resize(img, [100,100])\n",
    "    print(label)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {depth: (), height: (), image_raw: (), label: (), width: ()}, types: {depth: tf.int64, height: tf.int64, image_raw: tf.string, label: tf.int64, width: tf.int64}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "dataset = raw_image_dataset.map(_parse_image_function)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(91, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"args_3:0\", shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((100, 100, 3), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset.map(decode_img)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7cc85bf80302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "x,y = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91\n",
      " 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91\n",
      " 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91\n",
      " 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91\n",
      " 91 91 91 91], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i,k in train_data.take(1):\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ShuffleDataset' object has no attribute 'datad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-103c13ae3d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mdatad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ShuffleDataset' object has no attribute 'datad'"
     ]
    }
   ],
   "source": [
    "image_feature_description = {\n",
    "\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "# 提供组装 数据方法\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "\n",
    "def format_img(data):\n",
    "   \n",
    "    img_raw = data[\"image_raw\"]\n",
    "    height = data[\"height\"]\n",
    "\n",
    "    wight = data[\"width\"]\n",
    "    label = data[\"label\"]\n",
    "    \n",
    "    img_tensor = tf.image.decode_jpeg(img_raw,channels=3)\n",
    "    #imgs = tf.image.resize(img_tensor, [10,10])\n",
    "    img = tf.image.convert_image_dtype(img_tensor, tf.float32)\n",
    "    \n",
    "    img = tf.image.resize(img, [100,100])\n",
    "    return img, label\n",
    "datad = dataset.map(format_img)\n",
    "train_data = datad.shuffle(10).datad.batch(batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               4719104   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,743,201\n",
      "Trainable params: 4,743,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new = models.Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', data_format=\"channels_last\",\n",
    "           input_shape=(100, 100,3)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model_new.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model_new.summary()\n",
    "\n",
    "# Compile the model\n",
    "# estimator_model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#     metrics=['accuracy'])\n",
    "# model_dir = \"/tmp/note-fruits-tfrecord/\"\n",
    "# est_model = tf.keras.estimator.model_to_estimator(keras_model=estimator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1000 steps\n",
      "Epoch 1/1000\n"
     ]
    }
   ],
   "source": [
    "model_new.fit(train_data, epochs=1000, steps_per_epoch=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
