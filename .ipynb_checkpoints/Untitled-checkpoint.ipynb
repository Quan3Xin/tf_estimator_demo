{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras import models\n",
    "gpus= tf.config.list_physical_devices('GPU') # tf2.1版本该函数不再是experimental\n",
    "print(gpus) # 前面限定了只使用GPU1(索引是从0开始的,本机有2张RTX2080显卡)\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True) # 其实gpus本身就只有一个元素\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1' \n",
    "# In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {depth: (), height: (), image_raw: (), label: (), width: ()}, types: {depth: tf.int64, height: tf.int64, image_raw: tf.string, label: tf.string, width: tf.int64}>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "dataset = raw_image_dataset.map(_parse_image_function)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple Braeburn': 0,\n",
       " 'Apple Crimson Snow': 1,\n",
       " 'Apple Golden 1': 2,\n",
       " 'Apple Golden 2': 3,\n",
       " 'Apple Golden 3': 4,\n",
       " 'Apple Granny Smith': 5,\n",
       " 'Apple Pink Lady': 6,\n",
       " 'Apple Red 1': 7,\n",
       " 'Apple Red 2': 8,\n",
       " 'Apple Red 3': 9,\n",
       " 'Apple Red Delicious': 10,\n",
       " 'Apple Red Yellow 1': 11,\n",
       " 'Apple Red Yellow 2': 12,\n",
       " 'Apricot': 13,\n",
       " 'Avocado': 14,\n",
       " 'Avocado ripe': 15,\n",
       " 'Banana': 16,\n",
       " 'Banana Lady Finger': 17,\n",
       " 'Banana Red': 18,\n",
       " 'Beetroot': 19,\n",
       " 'Blueberry': 20,\n",
       " 'Cactus fruit': 21,\n",
       " 'Cantaloupe 1': 22,\n",
       " 'Cantaloupe 2': 23,\n",
       " 'Carambula': 24,\n",
       " 'Cauliflower': 25,\n",
       " 'Cherry 1': 26,\n",
       " 'Cherry 2': 27,\n",
       " 'Cherry Rainier': 28,\n",
       " 'Cherry Wax Black': 29,\n",
       " 'Cherry Wax Red': 30,\n",
       " 'Cherry Wax Yellow': 31,\n",
       " 'Chestnut': 32,\n",
       " 'Clementine': 33,\n",
       " 'Cocos': 34,\n",
       " 'Dates': 35,\n",
       " 'Eggplant': 36,\n",
       " 'Ginger Root': 37,\n",
       " 'Granadilla': 38,\n",
       " 'Grape Blue': 39,\n",
       " 'Grape Pink': 40,\n",
       " 'Grape White': 41,\n",
       " 'Grape White 2': 42,\n",
       " 'Grape White 3': 43,\n",
       " 'Grape White 4': 44,\n",
       " 'Grapefruit Pink': 45,\n",
       " 'Grapefruit White': 46,\n",
       " 'Guava': 47,\n",
       " 'Hazelnut': 48,\n",
       " 'Huckleberry': 49,\n",
       " 'Kaki': 50,\n",
       " 'Kiwi': 51,\n",
       " 'Kohlrabi': 52,\n",
       " 'Kumquats': 53,\n",
       " 'Lemon': 54,\n",
       " 'Lemon Meyer': 55,\n",
       " 'Limes': 56,\n",
       " 'Lychee': 57,\n",
       " 'Mandarine': 58,\n",
       " 'Mango': 59,\n",
       " 'Mango Red': 60,\n",
       " 'Mangostan': 61,\n",
       " 'Maracuja': 62,\n",
       " 'Melon Piel de Sapo': 63,\n",
       " 'Mulberry': 64,\n",
       " 'Nectarine': 65,\n",
       " 'Nectarine Flat': 66,\n",
       " 'Nut Forest': 67,\n",
       " 'Nut Pecan': 68,\n",
       " 'Onion Red': 69,\n",
       " 'Onion Red Peeled': 70,\n",
       " 'Onion White': 71,\n",
       " 'Orange': 72,\n",
       " 'Papaya': 73,\n",
       " 'Passion Fruit': 74,\n",
       " 'Peach': 75,\n",
       " 'Peach 2': 76,\n",
       " 'Peach Flat': 77,\n",
       " 'Pear': 78,\n",
       " 'Pear Abate': 79,\n",
       " 'Pear Forelle': 80,\n",
       " 'Pear Kaiser': 81,\n",
       " 'Pear Monster': 82,\n",
       " 'Pear Red': 83,\n",
       " 'Pear Williams': 84,\n",
       " 'Pepino': 85,\n",
       " 'Pepper Green': 86,\n",
       " 'Pepper Red': 87,\n",
       " 'Pepper Yellow': 88,\n",
       " 'Physalis': 89,\n",
       " 'Physalis with Husk': 90,\n",
       " 'Pineapple': 91,\n",
       " 'Pineapple Mini': 92,\n",
       " 'Pitahaya Red': 93,\n",
       " 'Plum': 94,\n",
       " 'Plum 2': 95,\n",
       " 'Plum 3': 96,\n",
       " 'Pomegranate': 97,\n",
       " 'Pomelo Sweetie': 98,\n",
       " 'Potato Red': 99,\n",
       " 'Potato Red Washed': 100,\n",
       " 'Potato Sweet': 101,\n",
       " 'Potato White': 102,\n",
       " 'Quince': 103,\n",
       " 'Rambutan': 104,\n",
       " 'Raspberry': 105,\n",
       " 'Redcurrant': 106,\n",
       " 'Salak': 107,\n",
       " 'Strawberry': 108,\n",
       " 'Strawberry Wedge': 109,\n",
       " 'Tamarillo': 110,\n",
       " 'Tangelo': 111,\n",
       " 'Tomato 1': 112,\n",
       " 'Tomato 2': 113,\n",
       " 'Tomato 3': 114,\n",
       " 'Tomato 4': 115,\n",
       " 'Tomato Cherry Red': 116,\n",
       " 'Tomato Maroon': 117,\n",
       " 'Tomato Yellow': 118,\n",
       " 'Walnut': 119}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# the number of classes of images\n",
    "\n",
    "# 组装 label名称和标签名称 例如 {“name”：1}\n",
    "data_root_orig = \"/root/quan/fruits-360/Training/\"\n",
    "data_root = pathlib.Path(data_root_orig)\n",
    "label_name = sorted(item.name for item in data_root.glob('*/')\n",
    "                    if item.is_dir())\n",
    "values = [i for i in list(range(len(label_name)))]\n",
    "classes = dict(zip(label_name, values))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def input_fn(filenames, training):\n",
    "#     dataset = tf.data.TFRecordDataset(filenames)\n",
    "#     dataset = dataset.map(parse_data)\n",
    " \n",
    "#     if training:\n",
    "#         dataset = dataset.shuffle(buffer_size=50000)\n",
    "#     dataset = dataset.batch(FLAGS.batch_size)\n",
    "#     if training:\n",
    "#         dataset = dataset.repeat()\n",
    " \n",
    "#     iterator = dataset.make_one_shot_iterator()\n",
    "#     features, labels = iterator.get_next()\n",
    "#     return features, labels\n",
    "def input_fn( record_list):\n",
    "    list_ds = tf.data.TFRecordDataset(filenames = record_list)\n",
    "   \n",
    "    dataset = list_ds.map(_parse_image_function)\n",
    "    data = dataset.map(decode_img)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def decode_img(record_list):\n",
    "    list_ds = tf.data.TFRecordDataset(filenames = record_list)\n",
    "   \n",
    "    data = list_ds.map(_parse_image_function)\n",
    "    img_raw = data[\"image_raw\"]\n",
    "    height = data[\"height\"]\n",
    "    \n",
    "    wight = data[\"width\"]\n",
    "    label = data[\"label\"]\n",
    "    \n",
    "    print(img_raw, height, wight, \"000000\")\n",
    "    \n",
    "    img_tensor = tf.image.decode_jpeg(img_raw,channels=3)\n",
    "    #imgs = tf.image.resize(img_tensor, [10,10])\n",
    "    img = tf.image.convert_image_dtype(img_tensor, tf.float32)\n",
    "    \n",
    "    img = tf.image.resize(img, [100,100])\n",
    "    print(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/quan/fruits-360/tfrecord/tfrecord\n",
      "['train.tfrecord-091', 'train.tfrecord-083', 'train.tfrecord-067', 'train.tfrecord-026', 'train.tfrecord-058', 'train.tfrecord-016', 'train.tfrecord-109', 'train.tfrecord-003', 'train.tfrecord-111', 'train.tfrecord-056', 'train.tfrecord-114', 'train.tfrecord-012', 'train.tfrecord-046', 'train.tfrecord-119', 'train.tfrecord-037', 'train.tfrecord-066', 'train.tfrecord-039', 'train.tfrecord-081', 'train.tfrecord-075', 'train.tfrecord-106', 'train.tfrecord-117', 'train.tfrecord-110', 'train.tfrecord-076', 'train.tfrecord-034', 'train.tfrecord-018', 'train.tfrecord-055', 'train.tfrecord-059', 'train.tfrecord-017', 'train.tfrecord-000', 'train.tfrecord-080', 'train.tfrecord-112', 'train.tfrecord-022', 'train.tfrecord-072', 'train.tfrecord-021', 'train.tfrecord-100', 'train.tfrecord-097', 'train.tfrecord-108', 'train.tfrecord-040', 'train.tfrecord-053', 'train.tfrecord-062', 'train.tfrecord-029', 'train.tfrecord-019', 'train.tfrecord-050', 'train.tfrecord-116', 'train.tfrecord-044', 'train.tfrecord-086', 'train.tfrecord-010', 'train.tfrecord-071', 'train.tfrecord-009', 'train.tfrecord-103', 'train.tfrecord-089', 'train.tfrecord-082', 'train.tfrecord-073', 'train.tfrecord-049', 'train.tfrecord-090', 'train.tfrecord-052', 'train.tfrecord-087', 'train.tfrecord-005', 'train.tfrecord-011', 'train.tfrecord-063', 'train.tfrecord-064', 'train.tfrecord-051', 'train.tfrecord-107', 'train.tfrecord-101', 'train.tfrecord-102', 'train.tfrecord-065', 'train.tfrecord-028', 'train.tfrecord-006', 'train.tfrecord-014', 'train.tfrecord-025', 'train.tfrecord-078', 'train.tfrecord-047', 'train.tfrecord-001', 'train.tfrecord-035', 'train.tfrecord-007', 'train.tfrecord-096', 'train.tfrecord-032', 'train.tfrecord-033', 'train.tfrecord-118', 'train.tfrecord-041', 'train.tfrecord-013', 'train.tfrecord-038', 'train.tfrecord-068', 'train.tfrecord-113', 'train.tfrecord-088', 'train.tfrecord-027', 'train.tfrecord-070', 'train.tfrecord-061', 'train.tfrecord-069', 'train.tfrecord-084', 'train.tfrecord-048', 'train.tfrecord-099', 'train.tfrecord-115', 'train.tfrecord-023', 'train.tfrecord-094', 'train.tfrecord-060', 'train.tfrecord-045', 'train.tfrecord-043', 'train.tfrecord-098', 'train.tfrecord-105', 'train.tfrecord-002', 'train.tfrecord-095', 'train.tfrecord-104', 'train.tfrecord-057', 'train.tfrecord-079', 'train.tfrecord-015', 'train.tfrecord-031', 'train.tfrecord-008', 'train.tfrecord-093', 'train.tfrecord-085', 'train.tfrecord-036', 'train.tfrecord-020', 'train.tfrecord-024', 'train.tfrecord-004', 'train.tfrecord-042', 'train.tfrecord-092', 'train.tfrecord-054', 'train.tfrecord-077', 'train.tfrecord-074', 'train.tfrecord-030']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {depth: (), height: (), image_raw: (), label: (), width: ()}, types: {depth: tf.int64, height: tf.int64, image_raw: tf.string, label: tf.string, width: tf.int64}>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/root/quan/fruits-360/tfrecord/tfrecord/\")\n",
    "print(os.getcwd())\n",
    "name_list = [k for _, _ , k in os.walk(\".\")]\n",
    "print(name_list[0])\n",
    "name_list = name_list[0]\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filenames = [name_list])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Pineapple', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "image_feature_description = {\n",
    "\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "# 提供组装 数据方法\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "for i in dataset.take(1):\n",
    "    print(i[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'MapDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-357eddf66a69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# df_train = dataset.map(decode_img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# d_set = df_train.shuffle(20).batch(batch_size=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlable\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdecode_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-101-6023edc50d24>\u001b[0m in \u001b[0;36mdecode_img\u001b[0;34m(record_list)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parse_image_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mimg_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_raw\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'MapDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def read_and_decode(filename_queue, random_crop=False, random_clip=False, shuffle_batch=True):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      features={\n",
    "          'height': tf.FixedLenFeature([], tf.int64),\n",
    "          'width': tf.FixedLenFeature([], tf.int64),\n",
    "          'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "          'label': tf.FixedLenFeature([], tf.int64)\n",
    "      })\n",
    "\n",
    "    image = tf.decode_raw(features['image_raw'], tf.float64)\n",
    "    image = tf.reshape(image, [300,300,3])\n",
    "\n",
    "    mask = tf.decode_raw(features['mask_raw'], tf.float64)\n",
    "    mask = tf.reshape(mask, [300,300])\n",
    "\n",
    "    name = features['name']\n",
    "\n",
    "    label = features['label']\n",
    "    width = features['width']\n",
    "    height = features['height']\n",
    "\n",
    "#    if random_crop:\n",
    "#        image = tf.random_crop(image, [227, 227, 3])\n",
    "#    else:\n",
    "#        image = tf.image.resize_image_with_crop_or_pad(image, 227, 227)\n",
    "\n",
    "#    if random_clip:\n",
    "#        image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "\n",
    "    if shuffle_batch:\n",
    "        images, masks, names, labels, widths, heights = tf.train.shuffle_batch([image, mask, name, label, width, height],\n",
    "                                                batch_size=4,\n",
    "                                                capacity=8000,\n",
    "                                                num_threads=4,\n",
    "                                                min_after_dequeue=2000)\n",
    "    else:\n",
    "        images, masks, names, labels, widths, heights = tf.train.batch([image, mask, name, label, width, height],\n",
    "                                        batch_size=4,\n",
    "                                        capacity=8000,\n",
    "                                        num_threads=4)\n",
    "    return images, masks, names, labels, widths, heights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "furit_model = models.Sequential([\n",
    "    Conv2D(16,\n",
    "           1,\n",
    "          activation=\"relu\",\n",
    "          input_shape=(100,100,3)),\n",
    "    MaxPooling2D(),\n",
    "    Dense(512, activation='relu')\n",
    "    \n",
    "])\n",
    "furit_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_4jjb951\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_4jjb951', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator_model = models.Sequential([\n",
    "     Conv2D(16,\n",
    "           3,\n",
    "           padding='same',\n",
    "           activation='relu',\n",
    "           input_shape=(28, 28,3)),\n",
    "    Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "estimator_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "model_dir = \"/tmp/note-fruits-tfrecord/\"\n",
    "est_model = tf.keras.estimator.model_to_estimator(keras_model=estimator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126\n",
      "   136 175  26 166 255 247 127   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253\n",
      "   253 225 172 253 242 195  64   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253\n",
      "   251  93  82  82  56  39   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247\n",
      "   241   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43\n",
      "   154   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108\n",
      "     1   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253\n",
      "   119  25   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253\n",
      "   253 150  27   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93\n",
      "   252 253 187   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   249 253 249  64   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183\n",
      "   253 253 207   2   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253\n",
      "   253 250 182   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253\n",
      "   201  78   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81\n",
      "     2   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]]], shape=(1, 28, 28), dtype=uint8)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "# Read MNIST into Dataset\n",
    "d_train = tfio.IODataset.from_mnist(\n",
    "    '../train-images.idx3-ubyte').batch(1)\n",
    "sum  = 0\n",
    "for i in d_train.take(1):\n",
    "    print(i)\n",
    "print(sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
